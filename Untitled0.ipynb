{
 "metadata": {
  "name": "",
  "signature": "sha256:c812ad1157bdf7ccff3187ad4579c5825766699a3c9a67c805260d48a6f8a6cb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "history = .read().split('\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = pickle.load(open(r'history.pkl'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(figsize=(15, 8))\n",
      "plot(np.ones(len(a['acc'])), linestyle='--')\n",
      "plot(a['acc'], label='train acc')\n",
      "plot(a['loss'], label='train loss')\n",
      "plot(a['val_acc'], label='val acc')\n",
      "plot(a['val_loss'], label='val loss')\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load vqa_experiment.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append( \"../deep-learning-models/\")\n",
      "from vgg19 import VGG19\n",
      "from keras.preprocessing import image\n",
      "from imagenet_utils import preprocess_input\n",
      "from keras.models import Model\n",
      "from keras.preprocessing import image\n",
      "from imagenet_utils import preprocess_input\n",
      "import numpy as np\n",
      "\n",
      "from keras.layers import Input, merge\n",
      "from keras.layers.core import Flatten, Dense, Dropout, Reshape\n",
      "from keras.layers.core import TimeDistributedDense, RepeatVector, Permute, Lambda\n",
      "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
      "from keras.layers.convolutional import ZeroPadding2D\n",
      "from keras.optimizers import SGD\n",
      "import keras.backend as K\n",
      "\n",
      "base_model = VGG19(weights='imagenet')\n",
      "\n",
      "\n",
      "def repeat_1(x):\n",
      "    \"\"\"Wrap keras backend repeat.\"\"\"\n",
      "    return K.repeat_elements(x, 32, 2)\n",
      "\n",
      "def sum_(x):\n",
      "    \"\"\"Wrap keras backend sum.\"\"\"\n",
      "    return K.sum(x, axis=1)\n",
      "\n",
      "base_model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in base_model.layers:\n",
      "    print i.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query_in_size = 100\n",
      "query_embed_size = 100\n",
      "img_in = base_model.input\n",
      "input_question = Input(shape=(query_in_size,))\n",
      "f_1 = Model(input=img_in, output=base_model.get_layer('block3_pool').output)\n",
      "f_1 = f_1(img_in)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f_1 = Reshape((256, 28*28))(f_1)\n",
      "f_1 = Permute((2,1))(f_1)\n",
      "\n",
      "\n",
      "q_1   = Dense(query_embed_size, activation='relu')(input_question)  # Encode question\n",
      "# Add question embedding to each feature column\n",
      "q_1   = RepeatVector(28*28)(q_1)\n",
      "q_f   = merge([f_1, q_1], 'concat')\n",
      "# Estimate and apply attention per feature\n",
      "att_1 = TimeDistributedDense(1, activation=\"sigmoid\")(q_f)\n",
      "att_1 = Lambda(repeat_1, output_shape=(28*28, 256))(att_1)\n",
      "att_1 = merge([f_1, att_1], 'mul')\n",
      "# Reshape to the original feature map from previous layer\n",
      "att_1 = Permute((2,1))(att_1)\n",
      "f_1_att = Reshape((256, 28, 28))(att_1)\n",
      "\n",
      "block_4 = Model(input=base_model.get_layer('block4_conv1').input, \n",
      "                output=base_model.get_layer('block4_pool').output)\n",
      "# f_1 = f_1(img_in)\n",
      "\n",
      "\n",
      "# model = Model(input=[img_in, input_question], output=f_1_att)\n",
      "# model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img_path = \"../../../roaming/public_datasets/Birds/CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0010_796097.jpg\"\n",
      "img = image.load_img(img_path, target_size=(224, 224))\n",
      "x = image.img_to_array(img)\n",
      "x = np.expand_dims(x, axis=0)\n",
      "x = preprocess_input(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "block4pool = base_model.get_layer('fc1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out = block4pool(img_in)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = Model(input=img_in, output=out)\n",
      "model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load model.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "import numpy as np\n",
      "import warnings\n",
      "\n",
      "from keras.models import Model\n",
      "from keras.layers import Flatten, Dense, Input\n",
      "from keras.layers import Convolution2D, MaxPooling2D\n",
      "from keras.preprocessing import image\n",
      "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
      "from keras.utils.data_utils import get_file\n",
      "from keras import backend as K\n",
      "from imagenet_utils import decode_predictions, preprocess_input\n",
      "\n",
      "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_th_dim_ordering_th_kernels.h5'\n",
      "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
      "TH_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_th_dim_ordering_th_kernels_notop.h5'\n",
      "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
      "\n",
      "\n",
      "def VGG19(include_top=True, weights='imagenet',\n",
      "          input_tensor=None, query_embed_size=100,\n",
      "          query_in_size=300):\n",
      "    '''Instantiate the VGG19 architecture,\n",
      "    optionally loading weights pre-trained\n",
      "    on ImageNet. Note that when using TensorFlow,\n",
      "    for best performance you should set\n",
      "    `image_dim_ordering=\"tf\"` in your Keras config\n",
      "    at ~/.keras/keras.json.\n",
      "\n",
      "    The model and the weights are compatible with both\n",
      "    TensorFlow and Theano. The dimension ordering\n",
      "    convention used by the model is the one\n",
      "    specified in your Keras config file.\n",
      "\n",
      "    # Arguments\n",
      "        include_top: whether to include the 3 fully-connected\n",
      "            layers at the top of the network.\n",
      "        weights: one of `None` (random initialization)\n",
      "            or \"imagenet\" (pre-training on ImageNet).\n",
      "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
      "            to use as image input for the model.\n",
      "\n",
      "    # Returns\n",
      "        A Keras model instance.\n",
      "    '''\n",
      "    if weights not in {'imagenet', None}:\n",
      "        raise ValueError('The `weights` argument should be either '\n",
      "                         '`None` (random initialization) or `imagenet` '\n",
      "                         '(pre-training on ImageNet).')\n",
      "    # Determine proper input shape\n",
      "    if K.image_dim_ordering() == 'th':\n",
      "        if include_top:\n",
      "            input_shape = (3, 224, 224)\n",
      "        else:\n",
      "            input_shape = (3, None, None)\n",
      "    else:\n",
      "        if include_top:\n",
      "            input_shape = (224, 224, 3)\n",
      "        else:\n",
      "            input_shape = (None, None, 3)\n",
      "\n",
      "    if input_tensor is None:\n",
      "        img_input = Input(shape=input_shape)\n",
      "    else:\n",
      "        if not K.is_keras_tensor(input_tensor):\n",
      "            img_input = Input(tensor=input_tensor)\n",
      "        else:\n",
      "            img_input = input_tensor\n",
      "    \n",
      "    input_question = Input(shape=(query_in_size,))\n",
      "    # Block 1\n",
      "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv1')(img_input)\n",
      "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)\n",
      "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
      "\n",
      "    # Block 2\n",
      "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1')(x)\n",
      "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)\n",
      "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
      "\n",
      "    # Block 3\n",
      "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1')(x)\n",
      "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2')(x)\n",
      "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv3')(x)\n",
      "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv4')(x)\n",
      "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
      "    \n",
      "    # Attention for Block3  \n",
      "    # Create feature columns\n",
      "    f_1 = Reshape((256, 28*28), name='att1_reshape')(x)\n",
      "    f_1 = Permute((2,1), name='att1_permute')(f_1)\n",
      "    q_1   = Dense(query_embed_size, activation='relu', name='att1_q')(input_question)  # Encode question\n",
      "    # Add question embedding to each feature column\n",
      "    q_1   = RepeatVector(28*28, name='att1_repeat')(q_1)\n",
      "    q_f   = merge([f_1, q_1], 'concat', name='att1_concat')\n",
      "    # Estimate and apply attention per feature column\n",
      "    att_1 = TimeDistributedDense(1, activation=\"sigmoid\", name='att1_attention')(q_f)\n",
      "    att_1 = Lambda(repeat_1, output_shape=(28*28, 256), name=\"att1_lambda\")(att_1)\n",
      "    att_1 = merge([f_1, att_1], 'mul', name=\"att1_merge\")\n",
      "    # Reshape to the original feature map from previous layer\n",
      "    att_1 = Permute((2,1), name='att1_re-permute')(att_1)\n",
      "    x = Reshape((256, 28, 28), name='att1_re-reshape')(att_1)\n",
      " \n",
      "    # Block 4\n",
      "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1')(x)\n",
      "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv2')(x)\n",
      "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)\n",
      "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv4')(x)\n",
      "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
      "    \n",
      "    \n",
      "    # Attention for Block4\n",
      "    f_1 = Reshape((512, 14*14), name='att2_reshape')(x)\n",
      "    f_1 = Permute((2,1), name='att2_permute')(f_1)\n",
      "    q_1   = Dense(query_embed_size, activation='relu', name='att2_q')(input_question)  # Encode question\n",
      "    q_1   = RepeatVector(14*14, name='att2_repeat')(q_1)\n",
      "    q_f   = merge([f_1, q_1], 'concat', name='att2_concat')\n",
      "    att_1 = TimeDistributedDense(1, activation=\"sigmoid\", name='att2_attention')(q_f)\n",
      "    att_1 = Lambda(repeat_1, output_shape=(14*14, 512), name=\"att2_lambda\")(att_1)\n",
      "    att_1 = merge([f_1, att_1], 'mul', name=\"att2_merge\")\n",
      "    att_1 = Permute((2,1), name='att2_re-permute')(att_1)\n",
      "    x = Reshape((512, 14, 14), name='att2_re-reshape')(att_1)\n",
      "    \n",
      "\n",
      "    # Block 5\n",
      "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1')(x)\n",
      "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv2')(x)\n",
      "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)\n",
      "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv4')(x)\n",
      "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
      "    \n",
      "        \n",
      "    # Attention for Block5\n",
      "    f_1 = Reshape((512, 7*7), name='att3_reshape')(x)\n",
      "    f_1 = Permute((2,1), name='att3_permute')(f_1)\n",
      "    q_1   = Dense(query_embed_size, activation='relu', name='att3_q')(input_question)  # Encode question\n",
      "    q_1   = RepeatVector(7*7, name='att3_repeat')(q_1)\n",
      "    q_f   = merge([f_1, q_1], 'concat', name='att3_concat')\n",
      "    att_1 = TimeDistributedDense(1, activation=\"sigmoid\", name='att3_attention')(q_f)\n",
      "    att_1 = Lambda(repeat_1, output_shape=(7*7, 512), name=\"att3_lambda\")(att_1)\n",
      "    att_1 = merge([f_1, att_1], 'mul', name=\"att3_merge\")\n",
      "    att_1 = Permute((2,1), name='att3_re-permute')(att_1)\n",
      "    x = Reshape((512, 7, 7), name='att3_re-reshape')(att_1)\n",
      "\n",
      "    if include_top:\n",
      "        # Classification block\n",
      "        x = Flatten(name='flatten')(x)\n",
      "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
      "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
      "        x = Dense(1000, activation='softmax', name='predictions')(x)\n",
      "\n",
      "    # Create model\n",
      "    model = Model([img_input, input_question], x)\n",
      "\n",
      "    # load weights\n",
      "    if weights == 'imagenet':\n",
      "        print('K.image_dim_ordering:', K.image_dim_ordering())\n",
      "        if K.image_dim_ordering() == 'th':\n",
      "            if include_top:\n",
      "                weights_path = get_file('vgg19_weights_th_dim_ordering_th_kernels.h5',\n",
      "                                        TH_WEIGHTS_PATH,\n",
      "                                        cache_subdir='models')\n",
      "            else:\n",
      "                weights_path = get_file('vgg19_weights_th_dim_ordering_th_kernels_notop.h5',\n",
      "                                        TH_WEIGHTS_PATH_NO_TOP,\n",
      "                                        cache_subdir='models')\n",
      "            model.load_weights(weights_path, by_name=True)\n",
      "            if K.backend() == 'tensorflow':\n",
      "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
      "                              'are using the Theano '\n",
      "                              'image dimension ordering convention '\n",
      "                              '(`image_dim_ordering=\"th\"`). '\n",
      "                              'For best performance, set '\n",
      "                              '`image_dim_ordering=\"tf\"` in '\n",
      "                              'your Keras config '\n",
      "                              'at ~/.keras/keras.json.')\n",
      "                convert_all_kernels_in_model(model)\n",
      "        else:\n",
      "            if include_top:\n",
      "                weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
      "                                        TF_WEIGHTS_PATH,\n",
      "                                        cache_subdir='models')\n",
      "            else:\n",
      "                weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
      "                                        TF_WEIGHTS_PATH_NO_TOP,\n",
      "                                        cache_subdir='models')\n",
      "            model.load_weights(weights_path)\n",
      "            if K.backend() == 'theano':\n",
      "                convert_all_kernels_in_model(model)\n",
      "    return model\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vgg = VGG19(weights='imagenet', include_top=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'VGG19' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-33d63ba64d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'VGG19' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Freeze pre-trained VGG19 layers\n",
      "for layer in vgg.layers:\n",
      "    if  not layer.name[0] == 'a':\n",
      "        layer.trainable = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vgg.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vgg.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append( \"../deep-learning-models/\")\n",
      "from vgg19_hiearatt import VGG19_hieratt\n",
      "from keras.layers import Dense\n",
      "from keras.models import Model\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using Theano backend.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append( \"../deep-learning-models/\")\n",
      "from vgg19_hiearatt import VGG19_hieratt\n",
      "from keras.layers import Dense\n",
      "from keras.models import Model\n",
      "import numpy as np\n",
      "from keras.utils.np_utils import to_categorical"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using Theano backend.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "base_model = VGG19_hieratt(include_top=True, \n",
      "              query_in_size=10, \n",
      "              query_embed_size=20)\n",
      "x = base_model.output\n",
      "predictions = Dense(5, activation='softmax', name='aclassifier')(x)\n",
      "mref_model = Model(input=base_model.input, output=predictions)\n",
      "\n",
      "for layer in mref_model.layers:\n",
      "    if  not layer.name[0] == 'a':\n",
      "        layer.trainable = False\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K.image_dim_ordering: th\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/akadar/.local/lib/python2.7/site-packages/keras/layers/core.py:1112: UserWarning: TimeDistributedDense is deprecated, please use TimeDistributed(Dense(...)) instead.\n",
        "  warnings.warn('TimeDistributedDense is deprecated, '\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.load('mref_vgg.npz')\n",
      "data['train_data'].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(60000, 224, 224, 3)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = data['train_data']\n",
      "X_train = np.transpose(X_train, [0,3,1,2])\n",
      "y_train = data['train_targets']\n",
      "color_mapper = dict(zip(set(y_train), range(0, len(set(y_train)))))\n",
      "y_train =  map(lambda x: color_mapper[x], y_train)\n",
      "y_train  = to_categorical(y_train)\n",
      "print X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(60000, 3, 224, 224)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "queries_train = to_categorical(data['train_queries'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "base_model = VGG19_hieratt(include_top=True, \n",
      "                               query_in_size=10, \n",
      "                               query_embed_size=20)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K.image_dim_ordering: th\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "base_model.predict([X_train[0:10], queries_train[0:10]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "array([[ 0.55254531,  0.31339747,  0.88360238, ...,  0.        ,\n",
        "         0.72198105,  0.72873884],\n",
        "       [ 0.59784353,  0.46920061,  0.7408368 , ...,  0.17563686,\n",
        "         0.56024194,  0.6019817 ],\n",
        "       [ 0.62694788,  0.43550405,  0.71592271, ...,  0.11307308,\n",
        "         0.53042787,  0.68346995],\n",
        "       ..., \n",
        "       [ 0.38060859,  0.39739642,  1.03175628, ...,  0.1533725 ,\n",
        "         0.65837049,  0.88025522],\n",
        "       [ 0.57623225,  0.49948728,  0.73597801, ...,  0.14690655,\n",
        "         0.46354768,  0.66513115],\n",
        "       [ 0.73867816,  0.35152152,  0.86333048, ...,  0.        ,\n",
        "         0.59578997,  0.62315643]], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}